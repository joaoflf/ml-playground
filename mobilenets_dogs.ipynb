{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenets-dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/joaoflf/ml-playground/blob/master/mobilenets_dogs.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "F3FRTuRQ2ESv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation of the Mobilenets paper\n",
        "\n",
        "This is an implementation of the mobilenets architecture in tensorflow, using the Stanford Dogs Dataset to test its effectiveness and accuracy\n",
        "\n",
        "----\n",
        "\n",
        "Package imports and Tensorboard setup"
      ]
    },
    {
      "metadata": {
        "id": "sB496g2-1-2m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Kill Colab VM (if needed)\n",
        "#!kill -9 -1\n",
        "\n",
        "import os\n",
        "if not os.path.exists('./colab_utils'):\n",
        "  !git clone https://github.com/mixuala/colab_utils.git\n",
        "    \n",
        "import colab_utils.tboard\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from scipy.io import loadmat\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
        "ROOT = %pwd\n",
        "root_log_dir = os.path.join(ROOT, 'tf_logs')\n",
        "colab_utils.tboard.launch_tensorboard( bin_dir=ROOT, log_dir=root_log_dir )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtyL_HSq4paA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download, extract and load dataset"
      ]
    },
    {
      "metadata": {
        "id": "-E-4yhz12k_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "if not os.path.exists('./data'):\n",
        "  !mkdir data\n",
        "  !wget -O ./data/data.tar http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\n",
        "  !tar xvf ./data/data.tar -C ./data/\n",
        "  !wget -O ./data/images.tar http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
        "  !tar xvf ./data/images.tar -C ./data/\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UI-dmlTQhitz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_file = loadmat('./data/train_list.mat')\n",
        "train_list = train_file['file_list'].flatten()\n",
        "train_list = ['./data/Images/' + val for sublist in train_list for val in sublist]\n",
        "train_list = train_list[:len(train_list)//10]\n",
        "train_labels = train_file['labels'].astype(int).flatten()\n",
        "train_labels = train_labels[:len(train_list)] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XPcLGYjjNsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_variable( shape, name,):\n",
        "  initializer = tf.contrib.layers.xavier_initializer()\n",
        "  var = tf.Variable(initializer(shape=shape), name= name)\n",
        "  return var\n",
        "\n",
        "def depthwise_conv(input, name, channels, stride):\n",
        "\n",
        "  W = create_variable([3, 3, channels, 1], name='dw_weight')\n",
        "  tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, W)\n",
        "  b = create_variable([channels], name='dw_bias')\n",
        "  \n",
        "  conv = tf.nn.bias_add(tf.nn.depthwise_conv2d(input, W, strides=stride, padding='SAME'), b, name='dw_conv')\n",
        "  conv = tf.nn.relu6(tf.layers.batch_normalization(conv))\n",
        "  return conv\n",
        "\n",
        "def pointwise_conv(input, name, channels_in, channels_out):\n",
        "\n",
        "  W = create_variable([1, 1, channels_in, channels_out], name='pw_weight')\n",
        "  tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, W)\n",
        "  b = create_variable([channels_out], name='pw_bias')\n",
        "  \n",
        "  conv = tf.nn.bias_add(tf.nn.conv2d(input, W, strides=[1,1,1,1], padding='SAME'), b, name='pw_conv')\n",
        "  conv = tf.nn.relu6(tf.layers.batch_normalization(conv))\n",
        "  return conv\n",
        "\n",
        "def dw_separable_conv(input, name, channels_in, channels_out, stride):\n",
        "  dw_conv = depthwise_conv(input, name, channels_in, stride)\n",
        "  pw_conv = pointwise_conv(dw_conv, name, channels_in, channels_out)\n",
        "  return pw_conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmH_Nl7IOxss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_layers = [\n",
        "    {\n",
        "        'name': 'sep_dw_1',\n",
        "        'channels_in': 32,\n",
        "        'channels_out': 64,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_2',\n",
        "        'channels_in': 64,\n",
        "        'channels_out': 128,\n",
        "        'stride': 2\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_3',\n",
        "        'channels_in': 128,\n",
        "        'channels_out': 128,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_4',\n",
        "        'channels_in': 128,\n",
        "        'channels_out': 256,\n",
        "        'stride': 2\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_5',\n",
        "        'channels_in': 256,\n",
        "        'channels_out': 256,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_6',\n",
        "        'channels_in': 256,\n",
        "        'channels_out': 512,\n",
        "        'stride': 2\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_7',\n",
        "        'channels_in': 512,\n",
        "        'channels_out': 512,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_8',\n",
        "        'channels_in': 512,\n",
        "        'channels_out': 512,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_9',\n",
        "        'channels_in': 512,\n",
        "        'channels_out': 512,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_10',\n",
        "        'channels_in': 512,\n",
        "        'channels_out': 512,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_11',\n",
        "        'channels_in': 512,\n",
        "        'channels_out': 512,\n",
        "        'stride': 1\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_12',\n",
        "        'channels_in': 512,\n",
        "        'channels_out': 1024,\n",
        "        'stride': 2\n",
        "    },\n",
        "    {\n",
        "        'name': 'sep_dw_13',\n",
        "        'channels_in': 1024,\n",
        "        'channels_out': 1024,\n",
        "        'stride': 1,\n",
        "    }\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oywhD4RhGfWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "learning_rate=0.01\n",
        "momentum = 0.9\n",
        "num_epochs = 40\n",
        "batch_size = 100\n",
        "\n",
        "# Parse fn to read, decode and resize image, and return both image and label to dataset\n",
        "def _parse_function(filename, label):\n",
        "  image_string = tf.read_file(filename)\n",
        "  image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "  image_resized = tf.image.resize_images(image_decoded, [224, 224])\n",
        "  return image_resized, label\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  filenames = tf.placeholder(tf.string, shape=[None])\n",
        "  labels = tf.placeholder(tf.int64, shape=[None])\n",
        "\n",
        "  # Build dataset, feed list of filenames, labels, shuffle, batch, repeat and iterate.\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "  dataset = dataset.map(_parse_function)\n",
        "  dataset = dataset.shuffle(buffer_size=10000)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.repeat(num_epochs)\n",
        "  iterator = dataset.make_initializable_iterator()\n",
        "\n",
        "  #get outputs of each iteration to feed into model\n",
        "  next_image, next_label = iterator.get_next()\n",
        "  layers = []\n",
        "\n",
        "  #initial conv layer\n",
        "  init_conv_w = create_variable([3, 3, 3, 32],'initial_conv_w')\n",
        "  init_conv_b = create_variable([32],'initial_conv_b')\n",
        "  conv_1= tf.nn.relu(tf.layers.batch_normalization(tf.nn.bias_add(tf.nn.conv2d(next_image, init_conv_w, [1, 2, 2, 1], padding='SAME'),init_conv_b, name='initial_conv')))\n",
        "\n",
        "  #depthwise separable conv layers\n",
        "  layers.append(conv_1)\n",
        "\n",
        "  for layer in conv_layers:\n",
        "    with tf.variable_scope(layer['name']):\n",
        "      dw_sep_conv = dw_separable_conv(layers[len(layers)-1], layer['name'], layer['channels_in'], layer['channels_out'], [1,layer['stride'],layer['stride'],1])\n",
        "      layers.append(dw_sep_conv)\n",
        "\n",
        "  #Avg pool, FC and Softmax layers\n",
        "  avg_pool = tf.nn.avg_pool(layers[len(layers)-1], ksize=[1, 7, 7, 1], strides=[1, 1, 1, 1], padding='VALID', name='avg_pool')\n",
        "  avg_pool_flat = tf.reshape(avg_pool, [-1, 1024])\n",
        "\n",
        "  fc1_weights = create_variable([1024,120], 'fc1_w')\n",
        "  fc1_bias = create_variable([120],'fc1_b')\n",
        "  fc1 = tf.nn.bias_add(tf.matmul(avg_pool_flat, fc1_weights), fc1_bias, name='fc1')\n",
        "\n",
        "  softmax = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=fc1, labels=next_label, name='softmax')\n",
        "\n",
        "  #loss and accuracy \n",
        "  loss = tf.reduce_mean(softmax, name='loss') \n",
        "  loss_summary = tf.summary.scalar('Loss', loss)\n",
        "\n",
        "  optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, momentum=momentum).minimize(loss)\n",
        "\n",
        "  pred_class = tf.argmax(fc1,1)\n",
        "  actual_class = next_label\n",
        "\n",
        "  correct_pred = tf.equal(pred_class, actual_class)\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  init = tf.global_variables_initializer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSnrMVc5kekA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdea56a7-b8cf-43a2-e0cc-b9649f224ea6"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Log_Hook(tf.train.SessionRunHook):\n",
        "  def __init__(self, loss, accuracy):\n",
        "    self.loss = loss\n",
        "    self.accuracy =accuracy\n",
        "\n",
        "  def begin(self):\n",
        "    self.step = 0\n",
        "    pass\n",
        "\n",
        "  def before_run(self, run_context):\n",
        "    self.step += 1\n",
        "    return tf.train.SessionRunArgs([self.loss, self.accuracy])  \n",
        "\n",
        "  def after_run(self, run_context, run_values):\n",
        "    if (self.step % 100 == 0):\n",
        "      loss_value, acc_value = run_values.results\n",
        "      print(\"Iteration: \" + str(self.step) + \", Minibatch Loss= \" + \"{:.3f}\".format(loss_value) + \", Training Accuracy= \" + \"{:.3f}\".format(acc_value))\n",
        "      \n",
        "\n",
        "with graph.as_default():\n",
        "  log_hook = Log_Hook(loss, accuracy)\n",
        "\n",
        "  now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "  logdir = \"{}/run-{}/\".format(root_log_dir, now)\n",
        "\n",
        "  summary_hook = tf.train.SummarySaverHook(save_steps=1, output_dir=logdir, summary_op=tf.summary.merge_all())\n",
        "  checkpoint_hook = tf.train.CheckpointSaverHook('./checkpoints', save_steps=100)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OP5dooJzbZa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2623aa07-ee8c-4aac-f333-34d0ab395eb3"
      },
      "cell_type": "code",
      "source": [
        "with graph.as_default():\n",
        "  with tf.train.MonitoredTrainingSession(hooks=[log_hook]) as sess:\n",
        "    sess.run(iterator.initializer, feed_dict={filenames: train_list, labels:train_labels})\n",
        "    while not sess.should_stop():\n",
        "      sess.run(optimizer)\n",
        "\n",
        "  print('Done!')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Iteration: 100, Minibatch Loss= 2.572, Training Accuracy= 0.070\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}