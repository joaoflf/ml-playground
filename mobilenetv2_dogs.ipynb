{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenetv2_dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/joaoflf/ml-playground/blob/master/mobilenetv2_dogs.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "T14zt4gBO5A1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Stanford Dogs Dataset on MobilenetV2\n",
        "\n",
        "Play with TensorFlow transfer learning capabilities, its Dataset API and train the model using MonitoredTrainingSession\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Download data and Mobilenets model"
      ]
    },
    {
      "metadata": {
        "id": "7sAx5jZS6S54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Kill Colab VM (if needed)\n",
        "#!kill -9 -1\n",
        "\n",
        "import os\n",
        "if not os.path.exists('./colab_utils'):\n",
        "  !git clone https://github.com/mixuala/colab_utils.git\n",
        "\n",
        "if not os.path.exists('./models'):\n",
        "  !git clone https://github.com/tensorflow/models/\n",
        "  # setup path\n",
        "  import sys\n",
        "  sys.path.append('/content/models/research/slim')\n",
        "  \n",
        "if not os.path.exists('./data'):\n",
        "  !mkdir data\n",
        "  !wget -O ./data/data.tar http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\n",
        "  !tar xvf ./data/data.tar -C ./data/\n",
        "  !wget -O ./data/images.tar http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
        "  !tar xvf ./data/images.tar -C ./data/\n",
        "if not os.path.exists('./mobilenets'):\n",
        "  !mkdir mobilenets\n",
        "  !wget -O ./mobilenets/mobilenet_v2.tgz https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz\n",
        "  !tar zxvf ./mobilenets/mobilenet_v2.tgz -C ./mobilenets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PurmJex1PjLr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import packages and setup TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "7mQ4BsP6tf0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "36065437-77d2-44d3-8fff-2e2ca1da8711"
      },
      "cell_type": "code",
      "source": [
        "import colab_utils.tboard\n",
        "import tensorflow as tf\n",
        "from nets.mobilenet import mobilenet_v2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from scipy.io import loadmat\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import time\n",
        "from pprint import pprint\n",
        "import scipy.misc\n",
        "from glob import glob\n",
        "\n",
        "ROOT = %pwd\n",
        "root_log_dir = os.path.join(ROOT, 'tf_logs')\n",
        "colab_utils.tboard.launch_tensorboard( bin_dir=ROOT, log_dir=root_log_dir )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ngrok installed\n",
            "status: tensorboard=True, ngrok=False\n",
            "tensorboard url= http://8594a1db.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://8594a1db.ngrok.io'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "9rMazJIKPqdD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load image filenames and labels"
      ]
    },
    {
      "metadata": {
        "id": "bl3d2eAA42eS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_file = loadmat('./data/train_list.mat')\n",
        "train_list = train_file['file_list'].flatten()\n",
        "train_list = ['./data/Images/' + val for sublist in train_list for val in sublist]\n",
        "train_list = train_list[:len(train_list)//10]\n",
        "train_labels = train_file['labels'].astype(int).flatten()\n",
        "train_labels = train_labels[:len(train_list)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O0-EcgwCP2gV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the graph, using the dataset API to feed the images"
      ]
    },
    {
      "metadata": {
        "id": "fWyOpeBW4-i_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "learning_rate=0.01\n",
        "momentum = 0.9\n",
        "num_epochs = 40\n",
        "batch_size = 100\n",
        "\n",
        "# Parse fn to read, decode and resize image, and return both image and label to dataset\n",
        "def _parse_function(filename, label):\n",
        "  image_string = tf.read_file(filename)\n",
        "  image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "  image_resized = tf.image.resize_images(image_decoded, [224, 224])\n",
        "  return image_resized, label\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  filenames = tf.placeholder(tf.string, shape=[None])\n",
        "  labels = tf.placeholder(tf.int64, shape=[None])\n",
        "\n",
        "  # Build dataset, feed list of filenames, labels, shuffle, batch, repeat and iterate.\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "  dataset = dataset.map(_parse_function)\n",
        "  dataset = dataset.shuffle(buffer_size=10000)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.repeat(num_epochs)\n",
        "  iterator = dataset.make_initializable_iterator()\n",
        "\n",
        "  #get outputs of each iteration to feed into model\n",
        "  next_image, next_label = iterator.get_next()\n",
        "\n",
        "  #import mobilenet graph, feeding in the image batch as input\n",
        "  with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=True)):\n",
        "    logits, endpoints = mobilenet_v2.mobilenet(next_image, num_classes=120)\n",
        "\n",
        "  #feed in logits from mobilenet and the labels batch to run softmax and calculate loss\n",
        "  softmax = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=next_label, name='softmax')\n",
        "  loss = tf.reduce_mean(softmax, name='loss')\n",
        "  loss_summary = tf.summary.scalar('Loss', loss)\n",
        "\n",
        "  #optimizing operation\n",
        "  global_step = tf.train.get_or_create_global_step()\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss,global_step=global_step)\n",
        "\n",
        "  #accuracy operation\n",
        "  correct_pred = tf.equal(tf.argmax(logits,1), next_label)\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "  accuracy_summary = tf.summary.scalar('Accuracy', accuracy)\n",
        "\n",
        "  saver = tf.train.Saver()\n",
        "  init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ho47tmB0RBLR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hooks to run in MonitoredTrainingSession. They include logging, writting summary to TensorBoard and saving checkpoints"
      ]
    },
    {
      "metadata": {
        "id": "3T9q0ZMtRNuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02e331be-79a6-46fe-9dc1-f50ed99fe817"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Log_Hook(tf.train.SessionRunHook):\n",
        "  def __init__(self, loss, accuracy):\n",
        "    self.loss = loss\n",
        "    self.accuracy =accuracy\n",
        "\n",
        "  def begin(self):\n",
        "    self.step = 0\n",
        "    pass\n",
        "\n",
        "  def before_run(self, run_context):\n",
        "    self.step += 1\n",
        "    return tf.train.SessionRunArgs([self.loss, self.accuracy])  \n",
        "\n",
        "  def after_run(self, run_context, run_values):\n",
        "    if (self.step % 100 == 0):\n",
        "      loss_value, acc_value = run_values.results\n",
        "      print(\"Iteration: \" + str(self.step) + \", Minibatch Loss= \" + \"{:.3f}\".format(loss_value) + \", Training Accuracy= \" + \"{:.3f}\".format(acc_value))\n",
        "      \n",
        "with graph.as_default():\n",
        "  log_hook = Log_Hook(loss, accuracy)\n",
        "\n",
        "  now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "  logdir = \"{}/run-{}/\".format(root_log_dir, now)\n",
        "\n",
        "  summary_hook = tf.train.SummarySaverHook(save_steps=1, output_dir=logdir, summary_op=tf.summary.merge_all())\n",
        "  checkpoint_hook = tf.train.CheckpointSaverHook('./checkpoints', save_steps=100)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uRUhz-RFRTFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run training session on 40 epochs and batches of 100"
      ]
    },
    {
      "metadata": {
        "id": "flDeVvXetRTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "0d1efd6b-be25-4e4e-f58a-9bbed8f9cdd7"
      },
      "cell_type": "code",
      "source": [
        "with graph.as_default():\n",
        "  with tf.train.MonitoredTrainingSession(hooks=[log_hook, summary_hook, checkpoint_hook]) as sess:\n",
        "    sess.run(iterator.initializer, feed_dict={filenames: train_list, labels:train_labels})\n",
        "    while not sess.should_stop():\n",
        "      sess.run(optimizer)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./checkpoints/model.ckpt.\n",
            "Iteration: 100, Minibatch Loss= 1.732, Training Accuracy= 0.430\n",
            "INFO:tensorflow:Saving checkpoints for 100 into ./checkpoints/model.ckpt.\n",
            "Iteration: 200, Minibatch Loss= 1.129, Training Accuracy= 0.650\n",
            "INFO:tensorflow:Saving checkpoints for 200 into ./checkpoints/model.ckpt.\n",
            "Iteration: 300, Minibatch Loss= 0.681, Training Accuracy= 0.770\n",
            "INFO:tensorflow:Saving checkpoints for 300 into ./checkpoints/model.ckpt.\n",
            "Iteration: 400, Minibatch Loss= 0.245, Training Accuracy= 0.910\n",
            "INFO:tensorflow:Saving checkpoints for 400 into ./checkpoints/model.ckpt.\n",
            "INFO:tensorflow:Saving checkpoints for 479 into ./checkpoints/model.ckpt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gZXOF-3kVnnM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test with an image with a Beagle pulled from the web. And... success!!"
      ]
    },
    {
      "metadata": {
        "id": "XeyNfYQU8hVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a85c030-1a0b-4dbe-88b0-337debab24c0"
      },
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./test'):\n",
        "  !mkdir test\n",
        "  !wget -O ./test/test_image.jpg https://www.what-dog.net/Images/faces2/scroll001.jpg\n",
        "    \n",
        "test_list = np.array(['./test/test_image.jpg'])\n",
        "\n",
        "with graph.as_default():\n",
        "  with tf.Session() as sess:\n",
        "    saver.restore(sess, './checkpoints/model.ckpt-479')\n",
        "    sess.run(iterator.initializer, feed_dict={filenames: test_list, labels:[1]})\n",
        "    logits_output = sess.run(logits)\n",
        "    idx = int(np.argmax(logits_output,1))\n",
        "    print(idx)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./checkpoints/model.ckpt-479\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}